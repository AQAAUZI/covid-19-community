{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Neo4j Knowledge Graph\n",
    "This notebook creates the COVID-19-Net knowledge graph by ingesting the .csv files in the Neo4j import directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/peter/Library/Application Support/Neo4j Desktop/Application/neo4jDatabases/database-4af96121-2328-4e2f-ba60-6d8b728a26d5/installation-4.0.3\n"
     ]
    }
   ],
   "source": [
    "NEO4J_HOME = Path(os.getenv('NEO4J_HOME'))\n",
    "print(NEO4J_HOME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Neo4j database if it is not running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directories in use:\n",
      "  home:         /Users/peter/Library/Application Support/Neo4j Desktop/Application/neo4jDatabases/database-4af96121-2328-4e2f-ba60-6d8b728a26d5/installation-4.0.3\n",
      "  config:       /Users/peter/Library/Application Support/Neo4j Desktop/Application/neo4jDatabases/database-4af96121-2328-4e2f-ba60-6d8b728a26d5/installation-4.0.3/conf\n",
      "  logs:         /Users/peter/Library/Application Support/Neo4j Desktop/Application/neo4jDatabases/database-4af96121-2328-4e2f-ba60-6d8b728a26d5/installation-4.0.3/logs\n",
      "  plugins:      /Users/peter/Library/Application Support/Neo4j Desktop/Application/neo4jDatabases/database-4af96121-2328-4e2f-ba60-6d8b728a26d5/installation-4.0.3/plugins\n",
      "  import:       /Users/peter/Library/Application Support/Neo4j Desktop/Application/neo4jDatabases/database-4af96121-2328-4e2f-ba60-6d8b728a26d5/installation-4.0.3/import\n",
      "  data:         /Users/peter/Library/Application Support/Neo4j Desktop/Application/neo4jDatabases/database-4af96121-2328-4e2f-ba60-6d8b728a26d5/installation-4.0.3/data\n",
      "  certificates: /Users/peter/Library/Application Support/Neo4j Desktop/Application/neo4jDatabases/database-4af96121-2328-4e2f-ba60-6d8b728a26d5/installation-4.0.3/certificates\n",
      "  run:          /Users/peter/Library/Application Support/Neo4j Desktop/Application/neo4jDatabases/database-4af96121-2328-4e2f-ba60-6d8b728a26d5/installation-4.0.3/run\n",
      "Starting Neo4j.\n",
      "Started neo4j (pid 5636). It is available at http://localhost:7474/\n",
      "There may be a short delay until the server is ready.\n",
      "See /Users/peter/Library/Application Support/Neo4j Desktop/Application/neo4jDatabases/database-4af96121-2328-4e2f-ba60-6d8b728a26d5/installation-4.0.3/logs/neo4j.log for current status.\n"
     ]
    }
   ],
   "source": [
    "status = !\"$NEO4J_HOME\"/bin/neo4j status\n",
    "status = str(status)\n",
    "if not 'Neo4j is running' in status:\n",
    "   !\"$NEO4J_HOME\"/bin/neo4j start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wait until Neo4j has started up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Neo4j is running at pid 5636']\n"
     ]
    }
   ],
   "source": [
    "status = !\"$NEO4J_HOME\"/bin/neo4j status\n",
    "status = str(status)\n",
    "while not 'Neo4j is running' in status:\n",
    "    time.sleep(15)\n",
    "    status = !\"$NEO4J_HOME\"/bin/neo4j status\n",
    "    status = str(status)\n",
    "    print(status)\n",
    "\n",
    "# wait until neo4j is ready to receive requests\n",
    "time.sleep(60)\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Cypher commands to create Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint: bolt://localhost:7687\n",
      "Username: neo4j\n",
      "Password: neo4jbinder\n",
      " \n",
      "----------------------------------------------\n",
      "Running 00a-Init.cypher:\n",
      " \n",
      "// delete all nodes\n",
      "MATCH (n) DETACH DELETE n;\n",
      "\n",
      "// delete all constraints and indices\n",
      "CALL apoc.schema.assert({},{});\n",
      "\n",
      "// create constraints and indices\n",
      "CREATE CONSTRAINT location ON (n:Location) ASSERT n.id IS UNIQUE;\n",
      "CREATE INDEX location_n FOR (n:Location) ON (n.name);\n",
      "CREATE CONSTRAINT world ON (n:World) ASSERT n.id IS UNIQUE;\n",
      "CREATE CONSTRAINT unregion ON (n:UNRegion) ASSERT n.id IS UNIQUE;\n",
      "CREATE CONSTRAINT unsubregion ON (n:UNSubRegion) ASSERT n.id IS UNIQUE;\n",
      "CREATE CONSTRAINT unintermediateregion ON (n:UNIntermediateRegion) ASSERT n.id IS UNIQUE;\n",
      "CREATE CONSTRAINT country ON (n:Country) ASSERT n.id IS UNIQUE;\n",
      "CREATE INDEX country_n FOR (n:Country) ON (n.name);\n",
      "CREATE CONSTRAINT admin1 ON (n:Admin1) ASSERT n.id IS UNIQUE;\n",
      "CREATE INDEX admin1_n FOR (n:Admin1) ON (n.name);\n",
      "CREATE CONSTRAINT usregion ON (n:USRegion) ASSERT n.id IS UNIQUE;\n",
      "CREATE CONSTRAINT usdivision ON (n:USDivision) ASSERT n.id IS UNIQUE;\n",
      "CREATE CONSTRAINT admin2 ON (n:Admin2) ASSERT n.id IS UNIQUE;\n",
      "CREATE INDEX admin2_f FOR (n:Admin2) ON (n.fips, n.stateFips);\n",
      "CREATE CONSTRAINT city ON (n:City) ASSERT n.id IS UNIQUE;\n",
      "CREATE CONSTRAINT cruiseship ON (n:CruiseShip) ASSERT n.id IS UNIQUE;\n",
      "                                   \n",
      "CREATE CONSTRAINT organism ON (n:Organism) ASSERT n.id IS UNIQUE;\n",
      "CREATE CONSTRAINT outbreak ON (n:Outbreak) ASSERT n.id IS UNIQUE;\n",
      "CREATE CONSTRAINT publication ON (n:Publication) ASSERT n.id IS UNIQUE;\n",
      "CREATE CONSTRAINT strain ON (n:Strain) ASSERT n.id IS UNIQUE;\n",
      "CREATE INDEX strain_n FOR (n:Strain) ON (n.name);\n",
      "CREATE CONSTRAINT variant ON (n:Variant) ASSERT n.id IS UNIQUE;\n",
      "CREATE CONSTRAINT gene ON (n:Gene) ASSERT n.id IS UNIQUE;\n",
      "CREATE INDEX gene_s FOR (n:Gene) ON (n.start);\n",
      "CREATE INDEX gene_e FOR (n:Gene) ON (n.end);\n",
      "CREATE CONSTRAINT protein ON (n:Protein) ASSERT n.id IS UNIQUE;\n",
      "CREATE CONSTRAINT proteinname ON (n:ProteinName) ASSERT n.id IS UNIQUE;\n",
      "CREATE INDEX proteinname_n FOR (n:ProteinName) ON (n.name);\n",
      "CREATE INDEX proteinname_a FOR (n:ProteinName) ON (n.accession);\n",
      "CREATE CONSTRAINT cases ON (n:Cases) ASSERT n.id IS UNIQUE;\n",
      "CREATE INDEX cases_d FOR (n:Cases) ON (n.date);\n",
      "\n",
      "// list constraints and indices\n",
      "CALL db.constraints();\n",
      "CALL db.indexes();\n",
      "\n",
      "\n",
      "\n",
      "label, key, keys, unique, action\n",
      "\"Gene\", \"end\", [\"end\"], FALSE, \"DROPPED\"\n",
      "\"Strain\", \"name\", [\"name\"], FALSE, \"DROPPED\"\n",
      "\"ProteinName\", \"name\", [\"name\"], FALSE, \"DROPPED\"\n",
      "\"ProteinName\", \"accession\", [\"accession\"], FALSE, \"DROPPED\"\n",
      "\"Location\", \"name\", [\"name\"], FALSE, \"DROPPED\"\n",
      "\"Cases\", \"date\", [\"date\"], FALSE, \"DROPPED\"\n",
      "\"Gene\", \"start\", [\"start\"], FALSE, \"DROPPED\"\n",
      "\"Country\", \"name\", [\"name\"], FALSE, \"DROPPED\"\n",
      "\"Admin1\", \"name\", [\"name\"], FALSE, \"DROPPED\"\n",
      "\"Admin2\", NULL, [\"fips\", \"stateFips\"], FALSE, \"DROPPED\"\n",
      "\"Cases\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"UNSubRegion\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"USRegion\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"Admin2\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"CruiseShip\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"Protein\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"City\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"Organism\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"Publication\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"Country\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"Outbreak\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"Strain\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"Gene\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"ProteinName\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"Location\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"World\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"UNRegion\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"UNIntermediateRegion\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"Admin1\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"USDivision\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "\"Variant\", \"id\", [\"id\"], TRUE, \"DROPPED\"\n",
      "name, description\n",
      "\"admin1\", \"CONSTRAINT ON ( admin1:Admin1 ) ASSERT (admin1.id) IS UNIQUE\"\n",
      "\"admin2\", \"CONSTRAINT ON ( admin2:Admin2 ) ASSERT (admin2.id) IS UNIQUE\"\n",
      "\"cases\", \"CONSTRAINT ON ( cases:Cases ) ASSERT (cases.id) IS UNIQUE\"\n",
      "\"city\", \"CONSTRAINT ON ( city:City ) ASSERT (city.id) IS UNIQUE\"\n",
      "\"country\", \"CONSTRAINT ON ( country:Country ) ASSERT (country.id) IS UNIQUE\"\n",
      "\"cruiseship\", \"CONSTRAINT ON ( cruiseship:CruiseShip ) ASSERT (cruiseship.id) IS UNIQUE\"\n",
      "\"gene\", \"CONSTRAINT ON ( gene:Gene ) ASSERT (gene.id) IS UNIQUE\"\n",
      "\"location\", \"CONSTRAINT ON ( location:Location ) ASSERT (location.id) IS UNIQUE\"\n",
      "\"organism\", \"CONSTRAINT ON ( organism:Organism ) ASSERT (organism.id) IS UNIQUE\"\n",
      "\"outbreak\", \"CONSTRAINT ON ( outbreak:Outbreak ) ASSERT (outbreak.id) IS UNIQUE\"\n",
      "\"protein\", \"CONSTRAINT ON ( protein:Protein ) ASSERT (protein.id) IS UNIQUE\"\n",
      "\"proteinname\", \"CONSTRAINT ON ( proteinname:ProteinName ) ASSERT (proteinname.id) IS UNIQUE\"\n",
      "\"publication\", \"CONSTRAINT ON ( publication:Publication ) ASSERT (publication.id) IS UNIQUE\"\n",
      "\"strain\", \"CONSTRAINT ON ( strain:Strain ) ASSERT (strain.id) IS UNIQUE\"\n",
      "\"unintermediateregion\", \"CONSTRAINT ON ( unintermediateregion:UNIntermediateRegion ) ASSERT (unintermediateregion.id) IS UNIQUE\"\n",
      "\"unregion\", \"CONSTRAINT ON ( unregion:UNRegion ) ASSERT (unregion.id) IS UNIQUE\"\n",
      "\"unsubregion\", \"CONSTRAINT ON ( unsubregion:UNSubRegion ) ASSERT (unsubregion.id) IS UNIQUE\"\n",
      "\"usdivision\", \"CONSTRAINT ON ( usdivision:USDivision ) ASSERT (usdivision.id) IS UNIQUE\"\n",
      "\"usregion\", \"CONSTRAINT ON ( usregion:USRegion ) ASSERT (usregion.id) IS UNIQUE\"\n",
      "\"variant\", \"CONSTRAINT ON ( variant:Variant ) ASSERT (variant.id) IS UNIQUE\"\n",
      "\"world\", \"CONSTRAINT ON ( world:World ) ASSERT (world.id) IS UNIQUE\"\n",
      "id, name, state, populationPercent, uniqueness, type, entityType, labelsOrTypes, properties, provider\n",
      "37, \"admin1\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"Admin1\"], [\"id\"], \"native-btree-1.0\"\n",
      "39, \"admin1_n\", \"ONLINE\", 100.0, \"NONUNIQUE\", \"BTREE\", \"NODE\", [\"Admin1\"], [\"name\"], \"native-btree-1.0\"\n",
      "73, \"admin2\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"Admin2\"], [\"id\"], \"native-btree-1.0\"\n",
      "75, \"admin2_f\", \"ONLINE\", 100.0, \"NONUNIQUE\", \"BTREE\", \"NODE\", [\"Admin2\"], [\"fips\", \"stateFips\"], \"native-btree-1.0\"\n",
      "8, \"cases\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"Cases\"], [\"id\"], \"native-btree-1.0\"\n",
      "10, \"cases_d\", \"POPULATING\", 66.5999984741211, \"NONUNIQUE\", \"BTREE\", \"NODE\", [\"Cases\"], [\"date\"], \"native-btree-1.0\"\n",
      "76, \"city\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"City\"], [\"id\"], \"native-btree-1.0\"\n",
      "34, \"country\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"Country\"], [\"id\"], \"native-btree-1.0\"\n",
      "36, \"country_n\", \"ONLINE\", 100.0, \"NONUNIQUE\", \"BTREE\", \"NODE\", [\"Country\"], [\"name\"], \"native-btree-1.0\"\n",
      "78, \"cruiseship\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"CruiseShip\"], [\"id\"], \"native-btree-1.0\"\n",
      "92, \"gene\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"Gene\"], [\"id\"], \"native-btree-1.0\"\n",
      "1, \"gene_e\", \"ONLINE\", 100.0, \"NONUNIQUE\", \"BTREE\", \"NODE\", [\"Gene\"], [\"end\"], \"native-btree-1.0\"\n",
      "94, \"gene_s\", \"ONLINE\", 100.0, \"NONUNIQUE\", \"BTREE\", \"NODE\", [\"Gene\"], [\"start\"], \"native-btree-1.0\"\n",
      "23, \"location\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"Location\"], [\"id\"], \"native-btree-1.0\"\n",
      "25, \"location_n\", \"ONLINE\", 100.0, \"NONUNIQUE\", \"BTREE\", \"NODE\", [\"Location\"], [\"name\"], \"native-btree-1.0\"\n",
      "80, \"organism\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"Organism\"], [\"id\"], \"native-btree-1.0\"\n",
      "82, \"outbreak\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"Outbreak\"], [\"id\"], \"native-btree-1.0\"\n",
      "2, \"protein\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"Protein\"], [\"id\"], \"native-btree-1.0\"\n",
      "4, \"proteinname\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"ProteinName\"], [\"id\"], \"native-btree-1.0\"\n",
      "7, \"proteinname_a\", \"ONLINE\", 100.0, \"NONUNIQUE\", \"BTREE\", \"NODE\", [\"ProteinName\"], [\"accession\"], \"native-btree-1.0\"\n",
      "6, \"proteinname_n\", \"ONLINE\", 100.0, \"NONUNIQUE\", \"BTREE\", \"NODE\", [\"ProteinName\"], [\"name\"], \"native-btree-1.0\"\n",
      "84, \"publication\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"Publication\"], [\"id\"], \"native-btree-1.0\"\n",
      "87, \"strain\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"Strain\"], [\"id\"], \"native-btree-1.0\"\n",
      "89, \"strain_n\", \"ONLINE\", 100.0, \"NONUNIQUE\", \"BTREE\", \"NODE\", [\"Strain\"], [\"name\"], \"native-btree-1.0\"\n",
      "32, \"unintermediateregion\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"UNIntermediateRegion\"], [\"id\"], \"native-btree-1.0\"\n",
      "28, \"unregion\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"UNRegion\"], [\"id\"], \"native-btree-1.0\"\n",
      "30, \"unsubregion\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"UNSubRegion\"], [\"id\"], \"native-btree-1.0\"\n",
      "71, \"usdivision\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"USDivision\"], [\"id\"], \"native-btree-1.0\"\n",
      "40, \"usregion\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"USRegion\"], [\"id\"], \"native-btree-1.0\"\n",
      "90, \"variant\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"Variant\"], [\"id\"], \"native-btree-1.0\"\n",
      "26, \"world\", \"ONLINE\", 100.0, \"UNIQUE\", \"BTREE\", \"NODE\", [\"World\"], [\"id\"], \"native-btree-1.0\"\n",
      " \n",
      "----------------------------------------------\n",
      "Running 00b-Organism.cypher:\n",
      " \n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///Organism.csv' AS row \n",
      "WITH row WHERE row.type='host'\n",
      "MERGE (h:Host{id: row.id})\n",
      "SET h.name = row.name, h.scientificName = row.scientificName\n",
      "RETURN count(h) as Host\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///Organism.csv' AS row \n",
      "WITH row WHERE row.type='pathogen'\n",
      "MERGE (p:Pathogen{id: row.id})\n",
      "SET p.name = row.name, p.scientificName = row.scientificName\n",
      "RETURN count(p) as Pathogen\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///Organism.csv' AS row \n",
      "MERGE (o:Organism{id: row.id})\n",
      "SET o.name = row.name, o.scientificName = row.scientificName, o.type = row.type\n",
      "RETURN count(o) as Organism\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///Organism.csv' AS row \n",
      "WITH row WHERE row.type='host'\n",
      "MATCH (h:Host{id: row.id})\n",
      "MATCH (o:Organism{id: row.id})\n",
      "MERGE (h)-[i:IS_A]->(o)\n",
      "RETURN count(i) as IS_A\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///Organism.csv' AS row \n",
      "WITH row WHERE row.type='pathogen'\n",
      "MATCH (p:Pathogen{id: row.id})\n",
      "MATCH (o:Organism{id: row.id})\n",
      "MERGE (p)-[i:IS_A]->(o)\n",
      "RETURN count(i) as IS_A\n",
      ";\n",
      "\n",
      "Host\n",
      "10\n",
      "Pathogen\n",
      "3\n",
      "Organism\n",
      "13\n",
      "IS_A\n",
      "10\n",
      "IS_A\n",
      "3\n",
      " \n",
      "----------------------------------------------\n",
      "Running 00c-Outbreak.cypher:\n",
      " \n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///Outbreak.csv' AS row \n",
      "MERGE (o:Outbreak{id: row.id})\n",
      "SET o.name = row.id, o.startDate = row.startDate, o.pathogen = row.pathogen\n",
      "RETURN count(o) as Outbreak\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///Outbreak.csv' AS row \n",
      "MATCH (p:Pathogen{id: row.pathogen})\n",
      "MATCH (o:Outbreak{id: row.id})\n",
      "MERGE(p)-[c:CAUSES]->(o)\n",
      "RETURN count(c) as CAUSES\n",
      ";\n",
      "                    \n",
      "Outbreak\n",
      "3\n",
      "CAUSES\n",
      "3\n",
      " \n",
      "----------------------------------------------\n",
      "Running 00e-GeoNamesCountry.cypher:\n",
      " \n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00e-GeoNamesCountry.csv' AS row \n",
      "MERGE (c:Country:Location{id: row.id})\n",
      "SET c.name = row.name, c.iso = row.iso, c.iso3 = row.iso3, c.population = row.population, c.areaSqKm = row.areaSqKm\n",
      "RETURN count(c) as Country\n",
      ";\n",
      "Country\n",
      "252\n",
      " \n",
      "----------------------------------------------\n",
      "Running 00f-GeoNamesAdmin1.cypher:\n",
      " \n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00f-GeoNamesAdmin1.csv' AS row \n",
      "MERGE (a:Admin1:Location{id: row.id})\n",
      "SET a.name = row.name, a.code = row.code, a.country = row.parentId\n",
      "RETURN count(a) as Admin1\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00f-GeoNamesAdmin1.csv' AS row \n",
      "MATCH (a:Admin1{id: row.id})\n",
      "MATCH (ct:Country{id: row.parentId})\n",
      "MERGE (a)-[i:IN]->(ct)\n",
      "RETURN count(i) as IN\n",
      ";\n",
      "Admin1\n",
      "3955\n",
      "IN\n",
      "3955\n",
      " \n",
      "----------------------------------------------\n",
      "Running 00g-GeoNamesAdmin2.cypher:\n",
      " \n",
      "USING PERIODIC COMMIT 500\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00g-GeoNamesAdmin2.csv' AS row \n",
      "MERGE (a:Admin2:Location{id: row.id})\n",
      "SET a.name = row.name\n",
      "RETURN count(a) as Admin2\n",
      ";\n",
      "USING PERIODIC COMMIT 500\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00g-GeoNamesAdmin2.csv' AS row \n",
      "MATCH (a2:Admin2{id: row.id})\n",
      "MATCH (a1:Admin1{id: row.parentId})\n",
      "MERGE (a2)-[i:IN]->(a1)\n",
      "RETURN count(i) as IN\n",
      ";\n",
      "Admin2\n",
      "44785\n",
      "IN\n",
      "44757\n",
      " \n",
      "----------------------------------------------\n",
      "Running 00h-GeoNamesCity.cypher:\n",
      " \n",
      "USING PERIODIC COMMIT 500\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00h-GeoNamesCity.csv' AS row \n",
      "MERGE (c:City:Location{id: row.id})\n",
      "SET c.name = row.name, c.population = row.population, c.elevation = row.elevation\n",
      "RETURN count(c) as City\n",
      ";\n",
      "USING PERIODIC COMMIT 500\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00h-GeoNamesCity.csv' AS row \n",
      "MATCH (l:Location{id: row.parentId})\n",
      "MATCH (c:City{id: row.id})\n",
      "MERGE (c)-[i:IN]->(l)\n",
      "RETURN count(i) as IN\n",
      ";\n",
      "City\n",
      "136922\n",
      "IN\n",
      "132972\n",
      " \n",
      "----------------------------------------------\n",
      "Running 00i-USCensusRegionDivisionState2017.cypher:\n",
      " \n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00i-USCensus2017Region.csv' AS row \n",
      "MERGE (r:USRegion:Location{id: row.id})\n",
      "SET r.name = row.name\n",
      "RETURN count(r) as Region\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00i-USCensus2017Division.csv' AS row \n",
      "MERGE (d:USDivision:Location{id: row.id})\n",
      "SET d.name = row.name\n",
      "RETURN count(d) as Division\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00i-USCensus2017State.csv' AS row \n",
      "MATCH (a:Admin1:Location{name: row.name, country: 'US'})\n",
      "SET a.fips = row.fips, a.division = row.division\n",
      "RETURN count(a) as FIPS\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00i-USCensus2017Region.csv' AS row \n",
      "MATCH (r:USRegion{id: row.id})\n",
      "MATCH (c:Country{id: row.parentId})\n",
      "MERGE (r)-[i:IN]->(c)\n",
      "RETURN count(i) as IN\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00i-USCensus2017Division.csv' AS row \n",
      "MATCH (d:USDivision{id: row.id})\n",
      "MATCH (r:USRegion{id: row.parentId})\n",
      "MERGE (d)-[i:IN]->(r)\n",
      "RETURN count(i) as IN\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00i-USCensus2017State.csv' AS row \n",
      "MATCH (a:Admin1{name: row.name, country: 'US'})\n",
      "MATCH (d:USDivision{id: row.parentId})\n",
      "MERGE (a)-[i:IN]->(d)\n",
      "RETURN count(i) as IN\n",
      ";\n",
      "\n",
      "Region\n",
      "4\n",
      "Division\n",
      "9\n",
      "FIPS\n",
      "50\n",
      "IN\n",
      "4\n",
      "IN\n",
      "9\n",
      "IN\n",
      "50\n",
      " \n",
      "----------------------------------------------\n",
      "Running 00j-USCensusCountyCity2017.cypher:\n",
      " \n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00j-USCensus2017County.csv' AS row \n",
      "MERGE (a:Admin2:Location{name: row.name})-[:IN]->(a1:Admin1{fips: row.stateFips})\n",
      "SET a.fips = row.fips, a.stateFips = row.stateFips\n",
      "RETURN count(a) as Admin2\n",
      ";\n",
      "\n",
      "Admin2\n",
      "3220\n",
      " \n",
      "----------------------------------------------\n",
      "Running 00k-UNRegion.cypher:\n",
      " \n",
      "MERGE (w:World:Location{id: \"m49:1\"})\n",
      "SET w.name = \"World\"\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00k-UNAll.csv' AS row\n",
      "MERGE (r:UNRegion:Location{id: row.UNRegionCode})\n",
      "SET r.name = row.UNRegion\n",
      "RETURN count(r) as UNRegion\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00k-UNAll.csv' AS row \n",
      "WITH row WHERE NOT row.UNSubRegion IS null\n",
      "MERGE (s:UNSubRegion:Location{id: row.UNSubRegionCode})\n",
      "SET s.name = row.UNSubRegion\n",
      "RETURN count(s) as UNSubRegion\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00k-UNAll.csv' AS row\n",
      "WITH row WHERE NOT row.UNIntermediateRegion IS null\n",
      "MERGE (n:UNIntermediateRegion:Location{id: row.UNIntermediateRegionCode})\n",
      "SET n.name = row.UNIntermediateRegion\n",
      "RETURN count(n) as UNIntermediateRegion\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00k-UNAll.csv' AS row \n",
      "MATCH (r:UNRegion{id: row.UNRegionCode})\n",
      "MATCH (w:World{id: \"m49:1\"})\n",
      "MERGE (r)-[i:IN]->(w)\n",
      "RETURN count(i) as IN\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00k-UNAll.csv' AS row\n",
      "WITH row WHERE NOT row.UNSubRegion IS null\n",
      "MATCH (s:UNSubRegion{id: row.UNSubRegionCode})\n",
      "MATCH (r:UNRegion{id: row.UNRegionCode})\n",
      "MERGE (s)-[i:IN]->(r)\n",
      "RETURN count(i) as IN\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00k-UNAll.csv' AS row \n",
      "WITH row WHERE NOT row.UNIntermediateRegion IS null\n",
      "MATCH (n:UNIntermediateRegion{id: row.UNIntermediateRegionCode})\n",
      "MATCH (s:UNSubRegion{id: row.UNSubRegionCode})\n",
      "MERGE (n)-[i:IN]->(s)\n",
      "RETURN count(i) as IN\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00k-UNRegion.csv' AS row \n",
      "MATCH (c:Country{iso3: row.iso3})\n",
      "MATCH (r:UNRegion{id: row.UNRegionCode})\n",
      "MERGE (c)-[i:IN]->(r)\n",
      "RETURN count(i) as IN\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00k-UNSubRegion.csv' AS row \n",
      "MATCH (c:Country{iso3: row.iso3})\n",
      "MATCH (s:UNSubRegion{id: row.UNSubRegionCode})\n",
      "MERGE (c)-[i:IN]->(s)\n",
      "RETURN count(i) as IN\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///00k-UNIntermediateRegion.csv' AS row \n",
      "MATCH (c:Country{iso3: row.iso3})\n",
      "MATCH (n:UNIntermediateRegion{id: row.UNIntermediateRegionCode})\n",
      "MERGE(c)-[i:IN]->(n)\n",
      "RETURN count(i) as IN\n",
      ";\n",
      "                                        \n",
      "\n",
      "UNRegion\n",
      "255\n",
      "UNSubRegion\n",
      "254\n",
      "UNIntermediateRegion\n",
      "107\n",
      "IN\n",
      "255\n",
      "IN\n",
      "254\n",
      "IN\n",
      "107\n",
      "IN\n",
      "1\n",
      "IN\n",
      "146\n",
      "IN\n",
      "107\n",
      " \n",
      "----------------------------------------------\n",
      "Running 00x-NodeMetadata.cypher:\n",
      " \n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///NodeMetadata.csv' AS row \n",
      "MERGE (n:NodeMetadata{name: row.name})\n",
      "SET n.shortDescription = row.shortDescription, n.description = row.description, n.example = row.example, n.details = row.details\n",
      "RETURN count(n) as NodeMetadata\n",
      ";\n",
      "NodeMetadata\n",
      "22\n",
      " \n",
      "----------------------------------------------\n",
      "Running 01a-NCBIStrain.cypher:\n",
      " \n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01a-NCBIStrain.csv' AS row \n",
      "WITH row WHERE NOT row.id IS null\n",
      "MERGE (s:Strain{id: row.id})\n",
      "SET s.name = row.name, s.taxonomy = row.taxonomy_id, s.collectionDate = row.collection_date,\n",
      "    s.hostTaxonomyId = row.host_taxonomy_id, s.sex = row.sex, s.age = row.age, \n",
      "    s.isolationSource = row.isolation_source\n",
      "RETURN count(s) as Strain\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01a-NCBIStrain.csv' AS row \n",
      "WITH row WHERE NOT row.taxonomy_id IS null\n",
      "MATCH (p:Pathogen{id: row.taxonomy_id})\n",
      "MATCH (s:Strain{id: row.id})\n",
      "MERGE (p)-[h:HAS_STRAIN]->(s)\n",
      "RETURN count(h) as HAS_STRAIN\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01a-NCBIStrain.csv' AS row \n",
      "WITH row WHERE NOT row.host_taxonomy_id IS null\n",
      "MATCH (h:Host{id: row.host_taxonomy_id})\n",
      "MATCH (s:Strain{id: row.id})\n",
      "MERGE (h)-[c:CARRIES]->(s)\n",
      "RETURN count(c) as CARRIES\n",
      ";\n",
      "                \n",
      "Strain\n",
      "1\n",
      "HAS_STRAIN\n",
      "1\n",
      "CARRIES\n",
      "1\n",
      " \n",
      "----------------------------------------------\n",
      "Running 01b-Nextstrain.cypher:\n",
      " \n",
      "USING PERIODIC COMMIT\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01b-Nextstrain.csv' AS row \n",
      "WITH row WHERE NOT row.id IS null\n",
      "MERGE (s:Strain{id: row.id}) \n",
      "SET s.name = row.name, s.taxonomyId = row.taxonomyId, s.collectionDate = row.collectionDate,\n",
      "    s.hostTaxonomyId = row.hostTaxonomyId, s.sex = row.sex, s.age = row.age, s.clade = row.clade,\n",
      "    s.exposureCountry = row.exposureCountry, s.exposureAdmin1 = row.exposureAdmin1\n",
      "RETURN count(s) as Strain\n",
      ";\n",
      "USING PERIODIC COMMIT\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01b-Nextstrain.csv' AS row \n",
      "WITH row WHERE NOT row.clade IS null\n",
      "MERGE (c:Clade{id: row.clade})\n",
      "RETURN count(c) as Clade\n",
      ";\n",
      "USING PERIODIC COMMIT\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01b-Nextstrain.csv' AS row \n",
      "WITH row WHERE NOT row.taxonomyId IS null\n",
      "MATCH (p:Pathogen{id: row.taxonomyId})\n",
      "MATCH (s:Strain{id: row.id})\n",
      "MERGE (p)-[h:HAS_STRAIN]->(s)\n",
      "RETURN count(h) as HAS_STRAIN\n",
      ";\n",
      "USING PERIODIC COMMIT\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01b-Nextstrain.csv' AS row \n",
      "WITH row WHERE NOT row.clade IS null\n",
      "MATCH (s:Strain{id: row.id})\n",
      "MATCH (c:Clade{id: row.clade})\n",
      "MERGE (s)-[h:HAS_CLADE]->(c)\n",
      "RETURN count(h) as HAS_CLADE\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01b-Nextstrain.csv' AS row \n",
      "WITH row WHERE NOT row.hostTaxonomyId IS null\n",
      "MATCH (h:Host{id: row.hostTaxonomyId})\n",
      "MATCH (s:Strain{id: row.id})\n",
      "MERGE (h)-[c:CARRIES]->(s)\n",
      "RETURN count(c) as CARRIES\n",
      ";\n",
      "Strain\n",
      "4214\n",
      "Clade\n",
      "4214\n",
      "HAS_STRAIN\n",
      "4214\n",
      "HAS_CLADE\n",
      "4214\n",
      "CARRIES\n",
      "4214\n",
      " \n",
      "----------------------------------------------\n",
      "Running 01c-NCBIRefSeq.cypher:\n",
      " \n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01c-NCBIRefSeq.csv' AS row \n",
      "MERGE (g:Gene{id: row.geneAccession + row.geneStart + row.geneEnd})\n",
      "SET g.name = row.geneName, g.start = row.geneStart, g.end = row.geneEnd\n",
      "RETURN count(g) as Gene\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01c-NCBIRefSeq.csv' AS row \n",
      "MATCH (gn:Strain{id: row.strainId})\n",
      "MATCH (g:Gene{id: row.geneAccession + row.geneStart + row.geneEnd})\n",
      "MERGE(gn)-[h:HAS]->(g)\n",
      "RETURN count(h) as Has\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01c-NCBIRefSeq.csv' AS row \n",
      "MERGE (p:Protein{id: row.id})\n",
      "SET p.name = row.proteinName, p.accession = row.proteinAccession, p.sequence = row.sequence, p.taxonomyId = row.taxonomyId\n",
      "RETURN count(p) as Protein\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01c-NCBIRefSeq.csv' AS row \n",
      "MERGE (p:ProteinName{id: row.id})\n",
      "SET p.name = row.proteinName, p.accession = row.proteinAccession\n",
      "RETURN count(p) as ProteinName\n",
      ";\n",
      "LOAD CSV WITH HEADERS FROM \"FILE:///01c-NCBIRefSeq.csv\" AS row\n",
      "MATCH (p:Protein{id: row.id})\n",
      "MATCH (pn:ProteinName{id: row.id})\n",
      "MERGE (p)-[n:NAMED_AS]->(pn)\n",
      "RETURN count(n) as NAMED_AS\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01c-NCBIRefSeq.csv' AS row \n",
      "MATCH (g:Gene{id: row.geneAccession + row.geneStart + row.geneEnd})\n",
      "MATCH (p:Protein{id: row.id})\n",
      "MERGE(g)-[e:ENCODES]->(p)\n",
      "RETURN count(e) as ENCODES\n",
      ";\n",
      "Gene\n",
      "28\n",
      "Has\n",
      "28\n",
      "Protein\n",
      "28\n",
      "ProteinName\n",
      "28\n",
      "NAMED_AS\n",
      "28\n",
      "ENCODES\n",
      "28\n",
      " \n",
      "----------------------------------------------\n",
      "Running 01d-CNCBStrain.cypher:\n",
      " \n",
      "USING PERIODIC COMMIT\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01d-CNCBStrain.csv' AS row \n",
      "MERGE (s:Strain{id: row.id}) \n",
      "SET s.name = row.name, s.alias = row.alias, s.taxonomyId = row.taxonomyId, s.collectionDate = row.collectionDate, s.hostTaxonomyId = row.hostTaxonomyId, s.location = row.location\n",
      "RETURN count(s) as Strain\n",
      ";\n",
      "USING PERIODIC COMMIT\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01d-CNCBStrain.csv' AS row\n",
      "MATCH (p:Pathogen{id: row.taxonomyId})\n",
      "MATCH (s:Strain{id: row.id})\n",
      "MERGE (p)-[h:HAS_STRAIN]->(s)\n",
      "RETURN count(h) as HAS_STRAIN\n",
      ";\n",
      "USING PERIODIC COMMIT\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01d-CNCBStrain.csv' AS row\n",
      "MATCH (h:Host{id: row.hostTaxonomyId})\n",
      "MATCH (s:Strain{id: row.id})\n",
      "MERGE (h)-[c:CARRIES]->(s)\n",
      "RETURN count(c) as CARRIES\n",
      ";\n",
      "USING PERIODIC COMMIT\n",
      "LOAD CSV WITH HEADERS\n",
      "FROM 'FILE:///01d-CNCBStrain.csv' AS row\n",
      "WITH row WHERE row.locationLevels='0'\n",
      "MATCH (c:Country{name: row.country})\n",
      "MATCH (s:Strain{id: row.id})\n",
      "MERGE (s)-[f:FOUND_IN]->(c)\n",
      "RETURN count(f) as FOUND_IN_COUNTRY\n",
      ";\n",
      "USING PERIODIC COMMIT\n",
      "LOAD CSV WITH HEADERS\n",
      "FROM 'FILE:///01d-CNCBStrain.csv' AS row\n",
      "WITH row WHERE row.locationLevels='1'\n",
      "MATCH (c:Country{name: row.country})<-[:IN*1..2]-(l1:Location{name: row.admin1})\n",
      "MATCH (s:Strain{id: row.id})\n",
      "MERGE (s)-[h:FOUND_IN]->(l1)\n",
      "RETURN count(h) as FOUND_IN_1\n",
      ";\n",
      "USING PERIODIC COMMIT\n",
      "LOAD CSV WITH HEADERS\n",
      "FROM 'FILE:///01d-CNCBStrain.csv' AS row\n",
      "WITH row WHERE row.locationLevels='2'\n",
      "MATCH (c:Country{name: row.country})<-[:IN*1..2]-(l1:Location{name: row.admin1})<-[:IN*]-(l2:Location{name: row.admin2})\n",
      "MATCH (s:Strain{id: row.id})\n",
      "MERGE (s)-[h:FOUND_IN]->(l2)\n",
      "RETURN count(h) as FOUND_IN_2\n",
      ";\n",
      "USING PERIODIC COMMIT\n",
      "LOAD CSV WITH HEADERS\n",
      "FROM 'FILE:///01d-CNCBStrain.csv' AS row\n",
      "WITH row WHERE row.locationLevels='3'\n",
      "MATCH (c:Country{name: row.country})<-[:IN]-(l1:Location{name: row.admin1})<-[:IN]-(l2:Location{name: row.admin2})<-[:IN]-(l3:Location{name: row.city})\n",
      "MATCH (s:Strain{id: row.id})\n",
      "MERGE (s)-[h:FOUND_IN]->(l3)\n",
      "RETURN count(h) as FOUND_IN_3\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01d-CNCBVariant.csv' AS row\n",
      "MERGE (v:Variant{id: row.referenceGenome + ':' + row.start + '-' + row.end + '-' + row.ref + '-' + row.alt})\n",
      "SET v.name = row.geneVariant, v.geneVariant = row.geneVariant, v.proteinVariant = row.proteinVariant, v.variantType = row.variantType, v.variantConsequence = row.variantConsequence, \n",
      "v.start = row.start, v.end = row.end, v.ref = row.ref, v.alt = row.alt, \n",
      "v.taxonomyId = row.taxonomyId, v.referenceGenome = row.referenceGenome\n",
      "RETURN count(v) as Variant\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01d-CNCBVariant.csv' AS row\n",
      "MATCH (s:Strain{name: row.name})\n",
      "MATCH (v:Variant{id: row.referenceGenome + ':' + row.start + '-' + row.end + '-' + row.ref + '-' + row.alt})\n",
      "MERGE (s)-[h:HAS_VARIANT]->(v)\n",
      "RETURN count(h) as HAS_VARIANT\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01d-CNCBVariant.csv' AS row\n",
      "MATCH (g:Gene) WHERE row.start >= g.start AND row.end <= g.end\n",
      "MATCH (v:Variant{id: row.referenceGenome + ':' + row.start + '-' + row.end + '-' + row.ref + '-' + row.alt})\n",
      "MERGE (g)-[h:HAS_VARIANT]->(v)\n",
      "RETURN count(h) as HAS_VARIANT\n",
      ";\n",
      "                    \n",
      "\n",
      "Strain\n",
      "22334\n",
      "HAS_STRAIN\n",
      "22334\n",
      "CARRIES\n",
      "22321\n",
      "FOUND_IN_COUNTRY\n",
      "2263\n",
      "FOUND_IN_1\n",
      "12802\n",
      "FOUND_IN_2\n",
      "4243\n",
      "FOUND_IN_3\n",
      "0\n",
      "Variant\n",
      "1781\n",
      "HAS_VARIANT\n",
      "1680\n",
      "HAS_VARIANT\n",
      "2579\n",
      " \n",
      "----------------------------------------------\n",
      "Running 01e-ProteinProteinInteraction.cypher:\n",
      " \n",
      "LOAD CSV WITH HEADERS FROM \"FILE:///01e-ProteinProteinInteractionProtein.csv\" AS row\n",
      "MERGE (p:Protein{id: row.id})\n",
      "SET p.name = row.name, p.accession = row.accession, p.pro_id = row.pro_id, \n",
      "    p.sequence = row.sequence, p.start = row.start, p.end = row.end, p.fullLength = row.fullLength, \n",
      "    p.taxonomyId = row.taxonomyId\n",
      "RETURN count(p) as Protein\n",
      ";\n",
      "LOAD CSV WITH HEADERS FROM \"FILE:///01e-ProteinProteinInteractionProtein.csv\" AS row\n",
      "MERGE (p:ProteinName{id: row.id})\n",
      "SET p.name = row.name, p.accession = row.accession, p.pro_id = row.pro_id\n",
      "RETURN count(p) as ProteinName\n",
      ";\n",
      "LOAD CSV WITH HEADERS FROM \"FILE:///01e-ProteinProteinInteractionProtein.csv\" AS row\n",
      "MATCH (p:Protein{id: row.id})\n",
      "MATCH (pn:ProteinName{id: row.id})\n",
      "MERGE (p)-[n:NAMED_AS]->(pn)\n",
      "RETURN count(n) as NAMED_AS\n",
      ";                     \n",
      "LOAD CSV WITH HEADERS FROM \"FILE:///01e-ProteinProteinInteraction.csv\" AS row\n",
      "MATCH (pa:Protein{id: row.id_a})\n",
      "MATCH (pb:Protein{id: row.id_b})\n",
      "MERGE (pa)-[i:INTERACTS_WITH]->(pb)\n",
      "RETURN count(i) as INTERACTS_WITH\n",
      ";\n",
      "\n",
      "\n",
      "Protein\n",
      "855\n",
      "ProteinName\n",
      "855\n",
      "NAMED_AS\n",
      "855\n",
      "INTERACTS_WITH\n",
      "951\n",
      " \n",
      "----------------------------------------------\n",
      "Running 01h-PMC-Accession.cypher:\n",
      " \n",
      "USING PERIODIC COMMIT\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01h-PMC-Accession.csv' AS row\n",
      "WITH row WHERE NOT row.accession IS null\n",
      "MERGE (p:Publication{id: row.id})\n",
      "RETURN count(p) as Publication\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01h-PMC-Accession.csv' AS row\n",
      "WITH row WHERE NOT row.accession IS null\n",
      "MATCH (s:Strain{id: row.accession})\n",
      "MATCH (p:Publication{id: row.id})\n",
      "MERGE (p)-[m:MENTIONS]->(s)\n",
      "RETURN count(m) as Publication_Strain\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///01h-PMC-Accession.csv' AS row\n",
      "WITH row WHERE NOT row.accession IS null\n",
      "MATCH (n:ProteinName{accession: row.accession})\n",
      "MATCH (p:Publication{id: row.id})\n",
      "MERGE (p)-[m:MENTIONS]->(n)\n",
      "RETURN count(m) as Publication_ProteinName\n",
      ";Publication\n",
      "10922\n",
      "Publication_Strain\n",
      "426\n",
      "Publication_ProteinName\n",
      "17566\n",
      " \n",
      "----------------------------------------------\n",
      "Running 02a-JHUCases.cypher:\n",
      " \n",
      "USING PERIODIC COMMIT 1000\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///02a-JHUCases.csv' AS row \n",
      "MERGE (c:Cases{id: 'COVID-19-' + row.date + row.countyFips + row.stateFips})\n",
      "SET c.name = 'COVID-19-' + row.date, c.date = date(row.date), c.cummulativeConfirmed = toInteger(row.cummulativeConfirmed), c.cummulativeDeaths = toInteger(row.cummulativeDeaths)\n",
      "RETURN count(c) as CASES\n",
      ";\n",
      "USING PERIODIC COMMIT 1000\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///02a-JHUCases.csv' AS row\n",
      "MATCH (c:Cases{id: 'COVID-19-' + row.date + row.countyFips + row.stateFips})\n",
      "MATCH (a:Admin2{fips: row.countyFips, stateFips: row.stateFips})\n",
      "MERGE (c)-[r:REPORTED_IN]->(a)\n",
      "RETURN count(r) as REPORTED_IN\n",
      ";\n",
      "USING PERIODIC COMMIT 1000\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///02a-JHUCases.csv' AS row\n",
      "MATCH (c:Cases{id: 'COVID-19-' + row.date + row.countyFips + row.stateFips})\n",
      "MATCH (o:Outbreak{id: 'COVID-19'})\n",
      "MERGE (c)-[r:RELATED_TO]->(o)\n",
      "RETURN count(r) as RELATED_TO\n",
      ";\n",
      "USING PERIODIC COMMIT 1000\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///02a-JHUCasesGlobalCountry.csv' AS row \n",
      "MERGE (c:Cases{id: 'COVID-19-' + row.date + row.country})\n",
      "SET c.name = 'COVID-19-' + row.date, c.date = date(row.date), c.cummulativeConfirmed = toInteger(row.cummulativeConfirmed), c.cummulativeDeaths = toInteger(row.cummulativeDeaths)\n",
      "RETURN count(c) as CASES\n",
      ";\n",
      "USING PERIODIC COMMIT 1000\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///02a-JHUCasesGlobalCountry.csv' AS row\n",
      "MATCH (c:Cases{id: 'COVID-19-' + row.date + row.country})\n",
      "MATCH (cn:Country{name: row.country})\n",
      "MERGE (c)-[r:REPORTED_IN]->(cn)\n",
      "RETURN count(r) as REPORTED_IN\n",
      ";\n",
      "USING PERIODIC COMMIT 1000\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///02a-JHUCasesGlobalCountry.csv' AS row\n",
      "MATCH (c:Cases{id: 'COVID-19-' + row.date + row.country})\n",
      "MATCH (o:Outbreak{id: 'COVID-19'})\n",
      "MERGE (c)-[r:RELATED_TO]->(o)\n",
      "RETURN count(r) as RELATED_TO\n",
      ";\n",
      "USING PERIODIC COMMIT 1000\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///02a-JHUCasesGlobalAdmin1.csv' AS row \n",
      "MERGE (c:Cases{id: 'COVID-19-' + row.date + row.country + row.admin1})\n",
      "SET c.name = 'COVID-19-' + row.date, c.date = date(row.date), c.cummulativeConfirmed = toInteger(row.cummulativeConfirmed), c.cummulativeDeaths = toInteger(row.cummulativeDeaths)\n",
      "RETURN count(c) as CASES\n",
      ";\n",
      "USING PERIODIC COMMIT 1000\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///02a-JHUCasesGlobalAdmin1.csv' AS row\n",
      "MATCH (c:Cases{id: 'COVID-19-' + row.date + row.country + row.admin1})\n",
      "MATCH (a:Admin1{name: row.admin1})-[:IN]->(cn:Country{name: row.country})\n",
      "MERGE (c)-[r:REPORTED_IN]->(a)\n",
      "RETURN count(r) as REPORTED_IN\n",
      ";\n",
      "USING PERIODIC COMMIT 1000\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///02a-JHUCasesGlobalAdmin1.csv' AS row\n",
      "MATCH (c:Cases{id: 'COVID-19-' + row.date + row.country + row.admin1})\n",
      "MATCH (o:Outbreak{id: 'COVID-19'})\n",
      "MERGE (c)-[r:RELATED_TO]->(o)\n",
      "RETURN count(r) as RELATED_TO\n",
      ";\n",
      "USING PERIODIC COMMIT 1000\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///02a-JHUCasesGlobalCruiseShip.csv' AS row \n",
      "MERGE (c:Cases{id: 'COVID-19-' + row.date + row.cruiseship})\n",
      "SET c.name = 'COVID-19-' + row.date, c.date = date(row.date), c.cummulativeConfirmed = toInteger(row.cummulativeConfirmed), c.cummulativeDeaths = toInteger(row.cummulativeDeaths)\n",
      "RETURN count(c) as CASES\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///02a-JHUCasesGlobalCruiseShip.csv' AS row \n",
      "MERGE (cs:CruiseShip:Location{id: row.cruiseship})\n",
      "SET cs.name = row.cruiseship\n",
      "RETURN count(cs) as CRUISESHIP\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///02a-JHUCasesGlobalCruiseShip.csv' AS row \n",
      "MATCH (cs:CruiseShip:Location{id: row.cruiseship})\n",
      "MATCH (w:World{id: \"m49:1\"})\n",
      "MERGE (cs)-[i:IN]->(w)\n",
      "RETURN count(i) as IN\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///02a-JHUCasesGlobalCruiseShip.csv' AS row\n",
      "MATCH (c:Cases{id: 'COVID-19-' + row.date + row.cruiseship})\n",
      "MATCH (cs:CruiseShip{id: row.cruiseship})\n",
      "MERGE (c)-[r:REPORTED_IN]->(cs)\n",
      "RETURN count(r) as REPORTED_IN\n",
      ";\n",
      "LOAD CSV WITH HEADERS \n",
      "FROM 'FILE:///02a-JHUCasesGlobalCruiseShip.csv' AS row\n",
      "MATCH (c:Cases{id: 'COVID-19-' + row.date + row.cruiseship})\n",
      "MATCH (o:Outbreak{id: 'COVID-19'})\n",
      "MERGE (c)-[r:RELATED_TO]->(o)\n",
      "RETURN count(r) as RELATED_TO\n",
      ";\n",
      " CASES\n",
      "199249\n",
      "REPORTED_IN\n",
      "196842\n",
      "RELATED_TO\n",
      "199249\n",
      "CASES\n",
      "18331\n",
      "REPORTED_IN\n",
      "18269\n",
      "RELATED_TO\n",
      "18331\n",
      "CASES\n",
      "6375\n",
      "REPORTED_IN\n",
      "6035\n",
      "RELATED_TO\n",
      "6375\n",
      "CASES\n",
      "339\n",
      "CRUISESHIP\n",
      "339\n",
      "IN\n",
      "339\n",
      "REPORTED_IN\n",
      "339\n",
      "RELATED_TO\n",
      "339\n"
     ]
    }
   ],
   "source": [
    "# TODO create a batch script for Windows\n",
    "#!./run_cyphers.sh\n",
    "!../scripts/run_cyphers.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 235.752210855484\n"
     ]
    }
   ],
   "source": [
    "end = time.time()\n",
    "print('time:', end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure to shutdown Neo4j!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j not running\n"
     ]
    }
   ],
   "source": [
    "!\"$NEO4J_HOME\"/bin/neo4j stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
